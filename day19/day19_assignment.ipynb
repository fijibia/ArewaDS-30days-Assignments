{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercises: Level 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function which count number of lines and number of words in a text\n",
    "\n",
    "def count_lines_and_words(obama_speech):\n",
    "    with open(\"obama_speech.txt\", \"r\") as file:\n",
    "        text = file.read()\n",
    "\n",
    "    lines = text.split('\\n')\n",
    "    num_lines = len(lines)\n",
    "\n",
    "    words = text.split()\n",
    "    num_words = len(words)\n",
    "\n",
    "    return num_lines, num_words\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = (\"C:/Users\\ACER USER\\Desktop\\ArewaDS-Workspace\\Data\\obama_speech.txt\")\n",
    "    lines, words = count_lines_and_words(\"C:\\Users\\ACER USER\\Desktop\\ArewaDS-Workspace\\Data\\obama_speech.txt\")\n",
    "\n",
    "    print(f\"Number of lines: {lines}\")\n",
    "    print(f\"Number of words: {words}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read michelle_obama_speech.txt file and count number of lines and words\n",
    "\n",
    "def count_lines_and_words(michelle_obama_speech):\n",
    "    with open(\"michelle_obama_speech.txt\", \"r\") as file:\n",
    "        text = file.read()\n",
    "\n",
    "    lines = text.split('\\n')\n",
    "    num_lines = len(lines)\n",
    "\n",
    "    words = text.split()\n",
    "    num_words = len(words)\n",
    "\n",
    "    return num_lines, num_words\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = \"C:\\Users\\ACER USER\\Desktop\\ArewaDS-Workspace\\Data\\michelle_obama_speech.txt\"\n",
    "    lines, words = count_lines_and_words(\"C:\\Users\\ACER USER\\Desktop\\ArewaDS-Workspace\\Data\\michelle_obama_speech.txt\")\n",
    "\n",
    "    print(f\"Number of lines: {lines}\")\n",
    "    print(f\"Number of words: {words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read donald_speech.txt file and count number of lines and words\n",
    "\n",
    "def count_lines_and_words(donald_speech):\n",
    "    with open(\"donald_speech.txt\", \"r\") as file:\n",
    "        text = file.read()\n",
    "\n",
    "    lines = text.split('\\n')\n",
    "    num_lines = len(lines)\n",
    "\n",
    "    words = text.split()\n",
    "    num_words = len(words)\n",
    "\n",
    "    return num_lines, num_words\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = \"C:\\Users\\ACER USER\\Desktop\\ArewaDS-Workspace\\Data\\donald_speech.txt\"\n",
    "    lines, words = count_lines_and_words(\"C:\\Users\\ACER USER\\Desktop\\ArewaDS-Workspace\\Data\\donald_speech.txt\")\n",
    "\n",
    "    print(f\"Number of lines: {lines}\")\n",
    "    print(f\"Number of words: {words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read melina_trump_speech.txt file and count number of lines and words\n",
    "\n",
    "def count_lines_and_words(melina_trump_speech):\n",
    "    with open(\"melina_trump_speech.txt\", \"r\") as file:\n",
    "        text = file.read()\n",
    "\n",
    "    lines = text.split('\\n')\n",
    "    num_lines = len(lines)\n",
    "\n",
    "    words = text.split()\n",
    "    num_words = len(words)\n",
    "\n",
    "    return num_lines, num_words\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = \"C:\\Users\\ACER USER\\Desktop\\ArewaDS-Workspace\\Data\\melina_trump_speech.txt\"\n",
    "    lines, words = count_lines_and_words(\"C:\\Users\\ACER USER\\Desktop\\ArewaDS-Workspace\\Data\\melina_trump_speech.txt\")\n",
    "\n",
    "    print(f\"Number of lines: {lines}\")\n",
    "    print(f\"Number of words: {words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the countries_data.json data file in data directory, create a function that finds the ten most spoken languages\n",
    "\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "def get_top_languages(countries_data):\n",
    "    try:\n",
    "        with open(countries_data, 'r', encoding='utf-8') as file:\n",
    "            data = json.load('countries_data')\n",
    "\n",
    "        languages = [entry['language'] for entry in data]\n",
    "\n",
    "        language_counts = Counter(languages)\n",
    "\n",
    "        top_languages = language_counts.most_common(top_n)\n",
    "\n",
    "        return top_languages\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {json_file_path}\")\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error decoding JSON in file: {json_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "json_file_path = 'C:\\Users\\ACER USER\\Desktop\\ArewaDS-Workspace\\Data\\countries_data.json'\n",
    "top_languages = get_top_languages(json_file_path)\n",
    "\n",
    "print(\"Top 10 most spoken languages:\")\n",
    "for rank, (language, count) in enumerate(top_languages, 1):\n",
    "    print(f\"{rank}. {language}: {count} occurrences\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the countries_data.json data file in data directory, create a function that creates a list of the ten most populated countries\n",
    "\n",
    "import json\n",
    "\n",
    "def get_top_populated_countries(countries_data, top_n=10):\n",
    "    try:\n",
    "        with open(countries_data, 'r', encoding='utf-8') as file:\n",
    "            data = json.load(file)\n",
    "\n",
    "        # Sort the data by population in descending order\n",
    "        sorted_data = sorted(data, key=lambda x: x['population'], reverse=True)\n",
    "\n",
    "        # Get the top N countries\n",
    "        top_countries = sorted_data[:top_n]\n",
    "\n",
    "        return top_countries\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {json_file_path}\")\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error decoding JSON in file: {json_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Example usage:\n",
    "json_file_path = 'countries_data.json'\n",
    "top_countries = get_top_populated_countries('C:\\Users\\ACER USER\\Desktop\\ArewaDS-Workspace\\Data\\countries_data.json')\n",
    "\n",
    "print(\"Top 10 most populated countries:\")\n",
    "for rank, country in enumerate(top_countries, 1):\n",
    "    print(f\"{rank}. {country['name']}: {country['population']} people\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercises: Level 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all incoming email addresses as a list from the email_exchange_big.txt file.\n",
    "\n",
    "import re\n",
    "\n",
    "def extract_email_addresses(email_exchanges_big):\n",
    "    try:\n",
    "        with open(email_exchanges_big, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "\n",
    "        # Use regular expression to find email addresses\n",
    "        email_pattern = re.compile(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b')\n",
    "        email_addresses = re.findall(email_pattern, content)\n",
    "\n",
    "        return email_addresses\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "file_path = 'C:\\Users\\ACER USER\\Desktop\\ArewaDS-Workspace\\Data\\email_exchanges_big.txt'  \n",
    "email_addresses = extract_email_addresses('email_exchanges_big')\n",
    "\n",
    "print(\"Extracted Email Addresses:\")\n",
    "for email in email_addresses:\n",
    "    print(email)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the most common words in the English language\n",
    "\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def find_most_common_words(data, num_words=10):\n",
    "    try:\n",
    "        # If the input is a file path, read the content\n",
    "        if isinstance(data, str) and data.endswith('.txt'):\n",
    "            with open(data, 'r', encoding='utf-8') as file:\n",
    "                content = file.read()\n",
    "        elif isinstance(data, str):\n",
    "            content = data\n",
    "        else:\n",
    "            raise ValueError(\"Invalid input. Provide either a string or a file path.\")\n",
    "\n",
    "        # Use regular expression to extract words\n",
    "        words = re.findall(r'\\b\\w+\\b', content.lower())\n",
    "\n",
    "        # Count word occurrences\n",
    "        word_counts = Counter(words)\n",
    "\n",
    "        # Get the most common words\n",
    "        most_common_words = word_counts.most_common(num_words)\n",
    "\n",
    "        return most_common_words\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {data}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Example usage:\n",
    "input_data = 'C:\\Users\\ACER USER\\Desktop\\ArewaDS-Workspace\\Data\\obama_speech.txt' \n",
    "num_words = 10\n",
    "common_words = find_most_common_words(input_data, num_words)\n",
    "\n",
    "print(f\"Top {num_words} Most Common Words:\")\n",
    "for word, count in common_words:\n",
    "    print(f\"{word}: {count} occurrences\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the function, find_most_frequent_words to find:\n",
    "\n",
    "def find_most_common_words(data, num_words=10):\n",
    "    try:\n",
    "        # If the input is a file path, read the content\n",
    "        if isinstance(data, str) and data.endswith('.txt'):\n",
    "            with open(data, 'r', encoding='utf-8') as file:\n",
    "                content = file.read()\n",
    "        elif isinstance(data, str):\n",
    "            content = data\n",
    "        else:\n",
    "            raise ValueError(\"Invalid input. Provide either a string or a file path.\")\n",
    "\n",
    "        # Use regular expression to extract words\n",
    "        words = re.findall(r'\\b\\w+\\b', content.lower())\n",
    "\n",
    "        # Count word occurrences\n",
    "        word_counts = Counter(words)\n",
    "\n",
    "        # Get the most common words\n",
    "        most_common_words = word_counts.most_common(num_words)\n",
    "\n",
    "        return most_common_words\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {data}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "#usage:\n",
    "file_path = (\"C:\\Users\\ACER USER\\Desktop\\ArewaDS-Workspace\\Data\\obama_speech.txt\") \n",
    "num_words = 10\n",
    "most_frequent_words = find_most_common_words(file_path, num_words)\n",
    "\n",
    "print(f\"Top {num_words} Most Frequent Words:\")\n",
    "for word, count in most_frequent_words:\n",
    "    print(f\"{word}: {count} occurrences\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a python application that checks similarity between two texts\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove non-alphanumeric characters and convert to lowercase\n",
    "    cleaned_text = re.sub(r'[^a-zA-Z0-9\\s]', '', text.lower())\n",
    "    return cleaned_text\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "def check_text_similarity(text1, text2):\n",
    "    cleaned_text1 = remove_stopwords(clean_text(text1))\n",
    "    cleaned_text2 = remove_stopwords(clean_text(text2))\n",
    "\n",
    "    # Vectorize the texts using TF-IDF\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectors = vectorizer.fit_transform([cleaned_text1, cleaned_text2])\n",
    "\n",
    "    # Calculate cosine similarity between the vectors\n",
    "    similarity = cosine_similarity(vectors[0], vectors[1])[0][0]\n",
    "\n",
    "    return similarity\n",
    "\n",
    "# usage:\n",
    "michelle_speech = open('michelle_speech.txt', 'r').read()\n",
    "melina_speech = open('melina_speech.txt', 'r').read()\n",
    "\n",
    "similarity_score = check_text_similarity(michelle_speech, melina_speech)\n",
    "\n",
    "print(f\"Similarity Score: {similarity_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the 10 most repeated words in the romeo_and_juliet.txt\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def find_most_repeated_words(file_path, num_words=10):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "\n",
    "        # Split the text into words and count occurrences\n",
    "        words = text.split()\n",
    "        word_counts = Counter(words)\n",
    "\n",
    "        # Get the most repeated words\n",
    "        most_repeated_words = word_counts.most_common(num_words)\n",
    "\n",
    "        return most_repeated_words\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# usage:\n",
    "file_path = (\"C:\\Users\\ACER USER\\Desktop\\ArewaDS-Workspace\\Data\\romeo_and_juliet.txt\")\n",
    "num_words = 10\n",
    "most_repeated_words = find_most_repeated_words(file_path, num_words)\n",
    "\n",
    "print(f\"Top {num_words} Most Repeated Words:\")\n",
    "for word, count in most_repeated_words:\n",
    "    print(f\"{word}: {count} occurrences\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the hacker news csv file and find out: \n",
    "\n",
    "import csv\n",
    "\n",
    "def count_lines(file_path, keyword):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            reader = csv.DictReader(file)\n",
    "\n",
    "            # Initialize counters\n",
    "            count_python = 0\n",
    "            count_javascript = 0\n",
    "            count_java_not_javascript = 0\n",
    "\n",
    "            # Iterate through the rows in the CSV file\n",
    "            for row in reader:\n",
    "                title = row['title']\n",
    "\n",
    "                # Count lines containing Python or python\n",
    "                if 'python' in title.lower():\n",
    "                    count_python += 1\n",
    "\n",
    "                # Count lines containing JavaScript, javascript, or Javascript\n",
    "                if 'javascript' in title.lower():\n",
    "                    count_javascript += 1\n",
    "\n",
    "                # Count lines containing Java and not JavaScript\n",
    "                if 'java' in title.lower() and 'javascript' not in title.lower():\n",
    "                    count_java_not_javascript += 1\n",
    "\n",
    "        return count_python, count_javascript, count_java_not_javascript\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Example usage:\n",
    "file_path = (\"C:\\Users\\ACER USER\\Desktop\\ArewaDS-Workspace\\Data\\hacker_news.csv\")\n",
    "count_python, count_javascript, count_java_not_javascript = count_lines(file_path, 'python')\n",
    "\n",
    "print(f\"Number of lines containing Python: {count_python}\")\n",
    "print(f\"Number of lines containing JavaScript: {count_javascript}\")\n",
    "print(f\"Number of lines containing Java and not JavaScript: {count_java_not_javascript}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
