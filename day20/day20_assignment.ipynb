{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercises: Day 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read this url and find the 10 most frequent words. romeo_and_juliet = 'http://www.gutenberg.org/files/1112/1112.txt'\n",
    "\n",
    "import requests\n",
    "from collections import Counter\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_text_from_url(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        text = soup.get_text()\n",
    "\n",
    "        return text\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching content from URL: {e}\")\n",
    "\n",
    "def find_most_frequent_words(text, num_words=10):\n",
    "    # Clean the text and split into words\n",
    "    words = text.split()\n",
    "    # Remove punctuation and convert to lowercase\n",
    "    cleaned_words = [word.strip('.,?!:;()[]{}\"\\'').lower() for word in words]\n",
    "\n",
    "    # Count word occurrences\n",
    "    word_counts = Counter(cleaned_words)\n",
    "\n",
    "    # Get the most frequent words\n",
    "    most_frequent_words = word_counts.most_common(num_words)\n",
    "\n",
    "    return most_frequent_words\n",
    "\n",
    "# usage:\n",
    "romeo_and_juliet_url = 'http://www.gutenberg.org/files/1112/1112.txt'\n",
    "romeo_and_juliet_text = get_text_from_url(romeo_and_juliet_url)\n",
    "\n",
    "if romeo_and_juliet_text:\n",
    "    most_frequent_words = find_most_frequent_words(romeo_and_juliet_text, num_words=10)\n",
    "\n",
    "    print(f\"Top 10 Most Frequent Words:\")\n",
    "    for word, count in most_frequent_words:\n",
    "        print(f\"{word}: {count} occurrences\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight Statistics:\n",
      "{'min': 2.0, 'max': 5.0, 'mean': 3.2238805970149254, 'median': 3.0, 'std_dev': 0.8779367862598653}\n",
      "\n",
      "Lifespan Statistics:\n",
      "{'min': 8.0, 'max': 18.0, 'mean': 12.074626865671641, 'median': 12.0, 'std_dev': 1.814645500809068}\n",
      "\n",
      "Frequency Table of Country and Breed of Cats:\n",
      "           origin              name  count\n",
      "0       Australia   Australian Mist      1\n",
      "1           Burma           Burmese      1\n",
      "2           Burma  European Burmese      1\n",
      "3          Canada            Cymric      1\n",
      "4          Canada            Sphynx      1\n",
      "..            ...               ...    ...\n",
      "62  United States          Savannah      1\n",
      "63  United States       Selkirk Rex      1\n",
      "64  United States          Snowshoe      1\n",
      "65  United States            Toyger      1\n",
      "66  United States    York Chocolate      1\n",
      "\n",
      "[67 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Read the cats API and cats_api = 'https://api.thecatapi.com/v1/breeds' and find\n",
    "\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "cats_api = 'https://api.thecatapi.com/v1/breeds'\n",
    "\n",
    "def get_cats_data(api_url):\n",
    "    try:\n",
    "        response = requests.get(api_url)\n",
    "        response.raise_for_status()\n",
    "        cats_data = response.json()\n",
    "        return cats_data\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching data from Cats API: {e}\")\n",
    "        return None\n",
    "\n",
    "def analyze_weight_lifespan(data):\n",
    "    weights = [cat.get('weight', {}).get('metric', '').split()[0] for cat in data]\n",
    "    lifespans = [cat.get('life_span', '').split()[0] for cat in data]\n",
    "\n",
    "    weights_numeric = [float(weight) for weight in weights if weight]\n",
    "    lifespans_numeric = [float(lifespan) for lifespan in lifespans if lifespan]\n",
    "\n",
    "    weight_stats = {\n",
    "        'min': np.min(weights_numeric),\n",
    "        'max': np.max(weights_numeric),\n",
    "        'mean': np.mean(weights_numeric),\n",
    "        'median': np.median(weights_numeric),\n",
    "        'std_dev': np.std(weights_numeric)\n",
    "    }\n",
    "\n",
    "    lifespan_stats = {\n",
    "        'min': np.min(lifespans_numeric),\n",
    "        'max': np.max(lifespans_numeric),\n",
    "        'mean': np.mean(lifespans_numeric),\n",
    "        'median': np.median(lifespans_numeric),\n",
    "        'std_dev': np.std(lifespans_numeric)\n",
    "    }\n",
    "\n",
    "    return weight_stats, lifespan_stats\n",
    "\n",
    "def create_frequency_table(data):\n",
    "    df = pd.DataFrame(data)\n",
    "    frequency_table = df.groupby(['origin', 'name']).size().reset_index(name='count')\n",
    "    return frequency_table\n",
    "\n",
    "# usage:\n",
    "cats_data = get_cats_data(cats_api)\n",
    "\n",
    "if cats_data:\n",
    "    weight_stats, lifespan_stats = analyze_weight_lifespan(cats_data)\n",
    "    print(\"Weight Statistics:\")\n",
    "    print(weight_stats)\n",
    "\n",
    "    print(\"\\nLifespan Statistics:\")\n",
    "    print(lifespan_stats)\n",
    "\n",
    "    # Create a frequency table of country and breed of cats\n",
    "    frequency_table_data = [{'origin': cat.get('origin', 'Unknown'), 'name': cat.get('name', 'Unknown')} for cat in cats_data]\n",
    "    frequency_table = create_frequency_table(frequency_table_data)\n",
    "    \n",
    "    print(\"\\nFrequency Table of Country and Breed of Cats:\")\n",
    "    print(frequency_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the countries API and find\n",
    "\n",
    "import requests\n",
    "\n",
    "countries_api = 'https://restcountries.com/v3.1/all'\n",
    "\n",
    "def get_countries_data(api_url):\n",
    "    try:\n",
    "        response = requests.get(api_url)\n",
    "        response.raise_for_status()\n",
    "        countries_data = response.json()\n",
    "        return countries_data\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching data from Countries API: {e}\")\n",
    "        return None\n",
    "\n",
    "def find_largest_countries(data, num_countries=10):\n",
    "    # Sorting countries by area in descending order\n",
    "    largest_countries = sorted(data, key=lambda x: x['area']['total'], reverse=True)[:num_countries]\n",
    "    return largest_countries\n",
    "\n",
    "def find_most_spoken_languages(data, num_languages=10):\n",
    "    # Extracting languages from all countries\n",
    "    all_languages = [language for country in data for language in country.get('languages', {}).values()]\n",
    "    \n",
    "    # Counting language occurrences\n",
    "    language_counts = dict(sorted([(language, all_languages.count(language)) for language in set(all_languages)], key=lambda x: x[1], reverse=True)[:num_languages])\n",
    "    \n",
    "    return language_counts\n",
    "\n",
    "def total_number_of_languages(data):\n",
    "    # Extracting unique languages from all countries\n",
    "    all_languages = set(language for country in data for language in country.get('languages', {}).values())\n",
    "    return len(all_languages)\n",
    "\n",
    "# usage:\n",
    "countries_data = get_countries_data(countries_api)\n",
    "\n",
    "if countries_data:\n",
    "    # Find the 10 largest countries\n",
    "    largest_countries = find_largest_countries(countries_data)\n",
    "    print(\"\\n10 Largest Countries:\")\n",
    "    for country in largest_countries:\n",
    "        print(f\"{country['name']['common']}: {country['area']['total']} square kilometers\")\n",
    "\n",
    "    # Find the 10 most spoken languages\n",
    "    most_spoken_languages = find_most_spoken_languages(countries_data)\n",
    "    print(\"\\n10 Most Spoken Languages:\")\n",
    "    for language, count in most_spoken_languages.items():\n",
    "        print(f\"{language}: {count} countries\")\n",
    "\n",
    "    # Find the total number of languages\n",
    "    total_languages = total_number_of_languages(countries_data)\n",
    "    print(f\"\\nTotal Number of Languages: {total_languages}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
